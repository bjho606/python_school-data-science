{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c132f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import tree, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xl_file = '/Users/JaehoByun/JB/_School/2021_2 데이터사이언스/과제및시험/db_score_3_labels.xlsx'\n",
    "\n",
    "db_score = pd.read_excel(xl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "800898e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sno</th>\n",
       "      <th>homework</th>\n",
       "      <th>discussion</th>\n",
       "      <th>final</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19.37</td>\n",
       "      <td>0</td>\n",
       "      <td>30.10</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>30.10</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19.37</td>\n",
       "      <td>0</td>\n",
       "      <td>29.75</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>18.12</td>\n",
       "      <td>2</td>\n",
       "      <td>29.05</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2</td>\n",
       "      <td>21.35</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>19.37</td>\n",
       "      <td>0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>18.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sno  homework  discussion  final grade\n",
       "0     1     19.37           0  30.10     A\n",
       "1     2     20.00           0  30.10     A\n",
       "2     3     19.37           0  29.75     A\n",
       "3     4     18.12           2  29.05     A\n",
       "4     5     20.00           2  21.35     A\n",
       "..  ...       ...         ...    ...   ...\n",
       "87   88     20.00           0   2.80     C\n",
       "88   89     19.37           0   4.55     C\n",
       "89   90     18.75           0   0.00     C\n",
       "90   91      0.00           0   1.05     C\n",
       "91   92      5.00           0   0.00     C\n",
       "\n",
       "[92 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "940f80aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.37,  0.  , 30.1 ],\n",
       "       [20.  ,  0.  , 30.1 ],\n",
       "       [19.37,  0.  , 29.75],\n",
       "       [18.12,  2.  , 29.05],\n",
       "       [20.  ,  2.  , 21.35],\n",
       "       [19.37,  0.  , 32.2 ],\n",
       "       [19.37,  2.  , 28.7 ],\n",
       "       [16.87,  0.  , 25.9 ],\n",
       "       [19.37,  0.  , 21.7 ],\n",
       "       [20.  ,  0.  , 19.25],\n",
       "       [19.37,  0.  , 21.35],\n",
       "       [19.37,  0.  , 20.65],\n",
       "       [19.37,  0.  , 21.  ],\n",
       "       [20.  ,  0.  , 18.55],\n",
       "       [18.12,  0.  , 23.1 ],\n",
       "       [19.37,  0.  , 24.85],\n",
       "       [20.  ,  0.  , 18.55],\n",
       "       [19.37,  0.  , 18.55],\n",
       "       [19.37,  0.  , 24.5 ],\n",
       "       [19.37,  0.  , 20.65],\n",
       "       [19.37,  0.  , 12.95],\n",
       "       [16.87,  0.  , 15.05],\n",
       "       [19.37,  0.  , 17.5 ],\n",
       "       [19.37,  0.  , 18.9 ],\n",
       "       [19.37,  2.  , 10.15],\n",
       "       [16.87,  0.  , 18.9 ],\n",
       "       [19.37,  2.  , 22.05],\n",
       "       [19.37,  0.  , 11.9 ],\n",
       "       [16.25,  0.  , 22.4 ],\n",
       "       [16.87,  0.  , 19.95],\n",
       "       [15.  ,  0.  , 19.95],\n",
       "       [20.  ,  0.  , 12.6 ],\n",
       "       [19.37,  0.  , 19.95],\n",
       "       [20.  ,  2.  , 14.35],\n",
       "       [18.12,  0.  , 16.1 ],\n",
       "       [20.  ,  0.  , 14.  ],\n",
       "       [16.87,  0.  , 20.3 ],\n",
       "       [20.  ,  0.  , 16.45],\n",
       "       [13.75,  0.  , 14.35],\n",
       "       [20.  ,  2.  , 14.7 ],\n",
       "       [19.37,  0.  , 17.85],\n",
       "       [19.37,  0.  , 18.55],\n",
       "       [19.37,  0.  , 18.9 ],\n",
       "       [17.5 ,  0.  , 13.3 ],\n",
       "       [19.37,  0.  , 10.15],\n",
       "       [19.37,  0.  , 15.75],\n",
       "       [20.  ,  0.  ,  9.8 ],\n",
       "       [16.87,  0.  , 21.35],\n",
       "       [16.87,  0.  , 12.25],\n",
       "       [19.37,  0.  , 11.9 ],\n",
       "       [18.75,  0.  ,  4.55],\n",
       "       [17.5 ,  2.  , 14.  ],\n",
       "       [15.62,  0.  , 19.25],\n",
       "       [19.37,  0.  , 11.2 ],\n",
       "       [17.5 ,  0.  , 19.6 ],\n",
       "       [20.  ,  0.  , 14.7 ],\n",
       "       [16.87,  0.  , 10.85],\n",
       "       [20.  ,  0.  ,  4.55],\n",
       "       [17.5 ,  0.  , 12.6 ],\n",
       "       [19.37,  0.  ,  7.7 ],\n",
       "       [19.37,  0.  , 12.25],\n",
       "       [19.37,  0.  , 11.9 ],\n",
       "       [19.37,  0.  , 11.9 ],\n",
       "       [20.  ,  0.  ,  7.35],\n",
       "       [16.87,  0.  , 12.25],\n",
       "       [19.37,  2.  ,  7.35],\n",
       "       [19.37,  0.  , 14.35],\n",
       "       [19.37,  0.  , 11.2 ],\n",
       "       [19.37,  2.  , 11.2 ],\n",
       "       [16.87,  0.  ,  9.8 ],\n",
       "       [16.87,  0.  , 13.3 ],\n",
       "       [19.37,  0.  ,  7.35],\n",
       "       [19.37,  0.  ,  1.05],\n",
       "       [19.37,  2.  ,  0.  ],\n",
       "       [16.25,  0.  ,  2.8 ],\n",
       "       [19.37,  0.  , 11.9 ],\n",
       "       [15.62,  0.  ,  8.05],\n",
       "       [15.  ,  0.  ,  9.45],\n",
       "       [16.87,  0.  , 10.5 ],\n",
       "       [16.87,  0.  ,  1.4 ],\n",
       "       [18.12,  0.  , 10.15],\n",
       "       [20.  ,  0.  ,  5.25],\n",
       "       [19.37,  0.  ,  5.6 ],\n",
       "       [18.75,  0.  ,  1.05],\n",
       "       [19.37,  0.  ,  2.45],\n",
       "       [18.75,  0.  , 10.15],\n",
       "       [19.37,  0.  ,  2.1 ],\n",
       "       [20.  ,  0.  ,  2.8 ],\n",
       "       [19.37,  0.  ,  4.55],\n",
       "       [18.75,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  1.05],\n",
       "       [ 5.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = db_score.loc[:,['homework', 'discussion', 'final']]\n",
    "# X = [ (t['homework'], t['discussion'], t['final'] ) for t in db_score ]\n",
    "X = np.array(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a03d1fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [ 1 if (t == 'B') else -1 for t in db_score['grade']]\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "083a06fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "for t in db_score['grade']:\n",
    "    if t == 'A':\n",
    "        y.append(0)\n",
    "    elif t == 'B':\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(2)\n",
    "    \n",
    "y = np.array(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6c001eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_performance_eval(y, y_predict):\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    \n",
    "    for y, yp in zip(y,y_predict):\n",
    "        if y == 1 and yp == 1:\n",
    "            tp += 1\n",
    "        elif y == 1 and yp == -1:\n",
    "            fn += 1\n",
    "        elif y == -1 and yp == 1:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "\n",
    "    print(\"tp={}, tn={}, fp={}, fn={}\".format(tp,tn,fp,fn))\n",
    "\n",
    "#     accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "#     precision = (tp)/(tp+fp)\n",
    "#     recall = (tp)/(tp+fn)\n",
    "#     f1_score = 2*precision*recall / (precision+recall)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = (tp)/(tp+fp) if (tp+fp) != 0 else 0\n",
    "    recall = (tp)/(tp+fn) if (tp+fn) != 0 else 0\n",
    "    f1_score = 2*precision*recall / (precision+recall) if precision != 0 else 0\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5428b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_classification_performance_eval(y, y_predict):\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    \n",
    "    for y, yp in zip(y,y_predict):\n",
    "        if y == 0 and yp == 0 or y == 1 and yp == 1 or y == 2 and yp == 2:\n",
    "            tp += 1\n",
    "        elif y == 0 and yp != 0 or y == 1 and yp != 1 or y == 2 and yp != 2:\n",
    "            fn += 1\n",
    "        elif y != 0 and yp == 0 or y != 1 and yp == 1 or y != 2 and yp == 2:\n",
    "            fp += 1\n",
    "        elif y != 0 and yp != 0 or y != 1 and yp != 1 or y != 2 and yp != 2:\n",
    "            tn += 1\n",
    "\n",
    "    print(\"tp={}, tn={}, fp={}, fn={}\".format(tp,tn,fp,fn))\n",
    "\n",
    "#     accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "#     precision = (tp)/(tp+fp)\n",
    "#     recall = (tp)/(tp+fn)\n",
    "#     f1_score = 2*precision*recall / (precision+recall)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = (tp)/(tp+fp) if (tp+fp) != 0 else 0\n",
    "    recall = (tp)/(tp+fn) if (tp+fn) != 0 else 0\n",
    "    f1_score = 2*precision*recall / (precision+recall) if precision != 0 else 0\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "fd2e1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Algorithm 1] Decision Tree model classification\n",
    "def decision_tree_model(X_train, X_test, y_train, y_test):\n",
    "    classifier = tree.DecisionTreeClassifier()\n",
    "    dtree_model = classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_predict = dtree_model.predict(X_test)\n",
    "    print(y_test)\n",
    "    print(y_predict)\n",
    "\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print(accuracy_score(y_test, y_predict))\n",
    "    print(precision_score(y_test, y_predict))\n",
    "    print(recall_score(y_test, y_predict))\n",
    "    print(f1_score(y_test, y_predict))\n",
    "#     acc, prec, rec, f1 = classification_performance_eval(y_test, y_predict)\n",
    "\n",
    "#     return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "173e7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Algorithm 2] SVM(Support Vector Machine) model classification\n",
    "def svm_model(X_train, X_test, y_train, y_test):\n",
    "    classifier = svm.SVC(kernel='rbf', C=8, gamma=0.1)  # 여기를 조절해야댐\n",
    "    svm_model = classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_predict = svm_model.predict(X_test)\n",
    "    print(y_test)\n",
    "    print(y_predict)\n",
    "    \n",
    "    classification_report(y_test, y_predict)\n",
    "    print(accuracy_score(y_test, y_predict))\n",
    "    print(precision_score(y_test, y_predict))\n",
    "    print(recall_score(y_test, y_predict))\n",
    "    print(f1_score(y_test, y_predict))\n",
    "    \n",
    "#     acc, prec, rec, f1 = classification_performance_eval(y_test, y_predict)\n",
    "\n",
    "#     return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "01db7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Algorithm 3] Logistic Regression model classification\n",
    "def logistic_regression_model(X_train, X_test, y_train, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    classifier = LogisticRegression()\n",
    "    lg_model = classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_predict = lg_model.predict(X_test_scaled)\n",
    "    print(y_test)\n",
    "    print(y_predict)\n",
    "    \n",
    "    classification_report(y_test, y_predict)\n",
    "    print(accuracy_score(y_test, y_predict))\n",
    "    print(precision_score(y_test, y_predict))\n",
    "    print(recall_score(y_test, y_predict))\n",
    "    print(f1_score(y_test, y_predict))\n",
    "\n",
    "#     acc, prec, rec, f1 = classification_performance_eval(y_test, y_predict)\n",
    "\n",
    "#     return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "75b44576",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3d234eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 -1 -1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1\n",
      "  1 -1 -1 -1  1 -1 -1]\n",
      "[-1  1  1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1\n",
      "  1 -1  1 -1 -1 -1 -1]\n",
      "tp=4, tn=18, fp=4, fn=5\n",
      "< Decision Tree >\n",
      "accuracy=0.709677\n",
      "precision=0.500000\n",
      "recall=0.444444\n",
      "f1_score=0.470588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision_tree_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "acc, prec, rec, f1 = decision_tree_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"< Decision Tree >\")\n",
    "print(\"accuracy=%f\" %acc)\n",
    "print(\"precision=%f\" %prec)\n",
    "print(\"recall=%f\" %rec)\n",
    "print(\"f1_score=%f\" %f1)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ac491549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 -1 -1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1\n",
      "  1 -1 -1 -1  1 -1 -1]\n",
      "[ 1  1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1  1\n",
      "  1 -1  1 -1 -1  1 -1]\n",
      "tp=5, tn=17, fp=5, fn=4\n",
      "< SVM (Support Vector Machine) >\n",
      "accuracy=0.709677\n",
      "precision=0.500000\n",
      "recall=0.555556\n",
      "f1_score=0.526316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svm_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "acc, prec, rec, f1 = svm_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"< SVM (Support Vector Machine) >\")\n",
    "print(\"accuracy=%f\" %acc)\n",
    "print(\"precision=%f\" %prec)\n",
    "print(\"recall=%f\" %rec)\n",
    "print(\"f1_score=%f\" %f1)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d256ca41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 -1 -1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1\n",
      "  1 -1 -1 -1  1 -1 -1]\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1]\n",
      "tp=0, tn=22, fp=0, fn=9\n",
      "< Logistic Regression >\n",
      "accuracy=0.709677\n",
      "precision=0.000000\n",
      "recall=0.000000\n",
      "f1_score=0.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic_regression_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "acc, prec, rec, f1 = logistic_regression_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"< Logistic Regression >\")\n",
    "print(\"accuracy=%f\" %acc)\n",
    "print(\"precision=%f\" %prec)\n",
    "print(\"recall=%f\" %rec)\n",
    "print(\"f1_score=%f\" %f1)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e088a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "cdc0bf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 2 0 0 1 2 0 1 2 1 2 2 0 0 0 0 1 2 0 2 2 1 1 0 2 2 1 2 0]\n",
      "[0 1 1 2 0 0 1 1 0 1 2 0 2 2 0 0 0 0 2 0 0 0 2 1 1 0 1 2 0 2 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.91      0.77        11\n",
      "           1       0.62      0.56      0.59         9\n",
      "           2       0.88      0.64      0.74        11\n",
      "\n",
      "    accuracy                           0.71        31\n",
      "   macro avg       0.72      0.70      0.70        31\n",
      "weighted avg       0.73      0.71      0.71        31\n",
      "\n",
      "0.7096774193548387\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-d139ecbf3ba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # decision_tree_model(X_train, X_test, y_train, y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdecision_tree_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# acc, prec, rec, f1 = decision_tree_model(X_train, X_test, y_train, y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-219-4b46babe6123>\u001b[0m in \u001b[0;36mdecision_tree_model\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     \"\"\"\n\u001b[0;32m-> 1653\u001b[0;31m     p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[1;32m   1654\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                                                  \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1462\u001b[0m                                     pos_label)\n\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0m\u001b[1;32m   1292\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m                              % (y_type, average_options))\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "# # decision_tree_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "decision_tree_model(X_train, X_test, y_train, y_test)\n",
    "# acc, prec, rec, f1 = decision_tree_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# print(\"< Decision Tree >\")\n",
    "# print(\"accuracy=%f\" %acc)\n",
    "# print(\"precision=%f\" %prec)\n",
    "# print(\"recall=%f\" %rec)\n",
    "# print(\"f1_score=%f\" %f1)\n",
    "# print(\"\")\n",
    "\n",
    "# # svm_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "svm_model(X_train, X_test, y_train, y_test)\n",
    "# acc, prec, rec, f1 = svm_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# print(\"< SVM (Support Vector Machine) >\")\n",
    "# print(\"accuracy=%f\" %acc)\n",
    "# print(\"precision=%f\" %prec)\n",
    "# print(\"recall=%f\" %rec)\n",
    "# print(\"f1_score=%f\" %f1)\n",
    "# print(\"\")\n",
    "\n",
    "# # logistic_regression_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "logistic_regression_model(X_train, X_test, y_train, y_test)\n",
    "# acc, prec, rec, f1 = logistic_regression_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# print(\"< Logistic Regression >\")\n",
    "# print(\"accuracy=%f\" %acc)\n",
    "# print(\"precision=%f\" %prec)\n",
    "# print(\"recall=%f\" %rec)\n",
    "# print(\"f1_score=%f\" %f1)\n",
    "# print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab8241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
